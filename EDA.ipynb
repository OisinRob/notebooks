{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will go work through how a DS may approach understanding the contents of a new data set\n",
    "\n",
    "1) We will load the data\n",
    "\n",
    "2) View what columns are contained in it\n",
    "\n",
    "3) See what ones are the most nully\n",
    "\n",
    "4) Which ones have lots of repitition\n",
    "\n",
    "5) Maybe one or two more small tests\n",
    "\n",
    "6) Then introduce pandas profiling\n",
    "\n",
    "7) Go through and understand what this actually means\n",
    "\n",
    "8) React? Is there anything further that can be done with this?\n",
    "\n",
    "9) Broach the topic of some deeper analyses\n",
    "\n",
    "10) Missing No"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Load the data\n",
    "We will initially be using pandas for our exploration.\n",
    "\n",
    "Pandas is extremely useful for dealing with tabular files such as csvs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file we shall be exploring is from the Kaggle contest \"Home Credit Default Risk\" \n",
    "\n",
    "We will be examining the application_train file (its a pretty large file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('2016 School Explorer.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) View the columns\n",
    "Now that the dataframe has been loaded, lets give a \n",
    "quick check to see what columns are containd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there are so many columns (note the length=122 at the end of that string above) they will not all display by default. To ensure we can see them all we will use list comprehension to display the all in the window. To do so I have created the helper function below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_all(series):\n",
    "    l = [x for x in series]\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_all(df.columns)\n",
    "\n",
    "# If this looks alien to you, this is the equivilant of writing:\n",
    "#     for x in df.columns:\n",
    "#         x\n",
    "# Not 100% true, I should check to see what is needed to show the x value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) See what ones are the most nully\n",
    "Great clearly this is quite a large data set, but as anyone working with real world data will know, all is rarely as it seems. The data is likely not to be comprehensively filled. This can be due to issues in the data, but also can occur in perfectly clean data sets, take the 'OWN_CAR_AGE' column above, this may not be populated for entries that do not own a car.\n",
    "\n",
    "Lets see the nully ness of each of the columns and order them by nullyness. \n",
    "First we create a helper function to return the % of the cells in a column that are empty by counting the occupied cells and comparing it to the full length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_prec(df_column):\n",
    "    full_length = len(df_column)\n",
    "    occupied_cells = df_column.count()\n",
    "    return (full_length - occupied_cells) * 100/full_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then apply it to each column, storing the output as a list for ease of sorting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_null_records = [[null_prec(df[column]), column ] for column in df.columns]\n",
    "sorted(column_null_records)\n",
    "\n",
    "# Similar to this\n",
    "#     out_list = []\n",
    "#     for x in df.columns:\n",
    "#         out_list.append((column, null_prec(df[column])))\n",
    "#     out_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear that some of the columns are far less occupied than others, and not only this it appears that some of the colums group together in their nullyness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas_profiling \n",
    "\n",
    "profile = pandas_profiling.ProfileReport(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rejected_variables = profile.get_rejected_variables(threshold=0.9)\n",
    "rejected_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.description_set['table']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_out= profile.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "card_regex = ur\"(?<=<code>)[^<]+(?=</code></a> has a high cardinality: )\"\n",
    "missing_regex = ur\"(?<=<code>)[^<]+(?=</code></a> has \\d+ / 100.0% missing values )\"\n",
    "high_card = re.findall(regex, html_out)\n",
    "high_card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# high cardinality\n",
    "plot each value\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
